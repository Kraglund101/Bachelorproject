{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88265fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f6faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"C:/Users/frede/Desktop/Bachelorprojekt/datasets/VALID-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c022cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_from_json(json_path):\n",
    "    f = open(json_path)\n",
    "    json_file = json.load(f)\n",
    "    path_to_image_file = json_file[\"file_name\"]\n",
    "    \n",
    "    return(f\"C:/Users/frede/Desktop/Bachelorprojekt/datasets/VALID-dataset/{path_to_image_file}\")\n",
    "\n",
    "def find_image_from_json_simple(json_path):\n",
    "    f = open(json_path)\n",
    "    json_file = json.load(f)\n",
    "    path_to_image_file = json_file[\"file_name\"]\n",
    "    #print(path_to_image_file)\n",
    "    \n",
    "    return(os.path.join(dataset_dir,path_to_image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a5e7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a custom dataset class\n",
    "class firstDataset(Dataset):\n",
    "    def __init__(self, dataset_dir):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.label_files = (os.listdir(os.path.join(dataset_dir, \"label\")))\n",
    "        self.depth_files = (os.listdir(os.path.join(dataset_dir, \"depth\")))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        #path to image and depth image\n",
    "        current_image_path = find_image_from_json_simple(os.path.join(self.dataset_dir, \"label\", self.label_files[idx]))\n",
    "        current_depth_image_path = os.path.join(self.dataset_dir, \"depth\", self.depth_files[idx])\n",
    "        \n",
    "        #Read in image and depth image\n",
    "        image = cv2.imread(current_image_path).astype(float)\n",
    "        depth_image = cv2.imread(current_depth_image_path).astype(float)\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((256,256)),\n",
    "        ])\n",
    "        \n",
    "        image = transform(image)\n",
    "        depth_image = transform(depth_image)\n",
    "        \n",
    "        return image,depth_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640f145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf65d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input size: amount_img, channels, width, height\n",
    "def resize_256_256(inp):\n",
    "    return(F.interpolate(inp, size=(256,256), mode=\"bilinear\", align_corners=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b67119b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3428\\3783993891.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m#return(tensor_images,tensor_depth_images)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_dir' is not defined"
     ]
    }
   ],
   "source": [
    "def create_data_valid(path):\n",
    "    start_time = time.time()\n",
    "    images_list = []\n",
    "    depth_images_list = []\n",
    "    depth_images_no_rgb_list = []\n",
    "\n",
    "    t = []\n",
    "    ignore_indicies = list(range(2865,2928)) + list(range(2966,2972)) + list(range(2975,3029))\n",
    "    ignore_indicies_strings = [\"0\"+str(element)+\".png\" for element in ignore_indicies]\n",
    "    for i, (depth, label) in (enumerate(zip(os.listdir(os.path.join(path,\"depth\")), os.listdir(os.path.join(path,\"label\"))))):\n",
    "\n",
    "        \n",
    "        if depth not in ignore_indicies_strings:  \n",
    "            print(f\"appending {depth}\")\n",
    "            # Path to image and depth image\n",
    "            t.append((i,depth))\n",
    "            current_image_path = find_image_from_json_simple(os.path.join(path, \"label\", label))\n",
    "            current_depth_image_path = os.path.join(path,\"depth\", depth)\n",
    "\n",
    "            # Read in image and depth image\n",
    "\n",
    "            image = cv2.imread(current_image_path).astype(float)   \n",
    "            depth_image_r = cv2.imread(current_depth_image_path,-1)/256\n",
    "            depth_image_r = np.clip(depth_image_r, 0.001, 80, depth_image_r)\n",
    "\n",
    "            depth_image_r = np.expand_dims(depth_image_r, axis=2).repeat(3, axis=2)\n",
    "\n",
    "            image = resize_256_256(torch.from_numpy(image).unsqueeze(0).permute(0,3,1,2)).squeeze(0)\n",
    "            depth_image = resize_256_256(torch.from_numpy(depth_image_r).unsqueeze(0).permute(0,3,1,2)).squeeze(0)\n",
    "            depth_image_no_rgb = (resize_256_256(torch.from_numpy(depth_image_r).unsqueeze(0).permute(0,3,1,2))[:,:1,:,:]).squeeze(0) # (1,1,256,256)\n",
    "            \n",
    "            # Add image tensor and depth image tensor to lists\n",
    "            images_list.append(image.half())\n",
    "            depth_images_list.append(depth_image.half())\n",
    "            depth_images_no_rgb_list.append(depth_image_no_rgb.half())\n",
    "\n",
    "            \n",
    "        else:\n",
    "            print(f\"skipped {depth}\")\n",
    "        \n",
    "           \n",
    "\n",
    "    tensor_images = torch.stack(images_list)\n",
    "    tensor_depth_images = torch.stack(depth_images_list)\n",
    "    tensor_depth_images_no_rgb = torch.stack(depth_images_no_rgb_list)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    \n",
    "    #save tensors locally to free up memory\n",
    "    if not os.path.exists(\"VALID_tensors\"):\n",
    "        os.makedirs(\"VALID_tensors\")\n",
    "    torch.save(tensor_images, \"VALID_tensors/VALID_tensor_images.pt\")\n",
    "    torch.save(tensor_depth_images, \"VALID_tensors/VALID_tensor_depth_images.pt\")\n",
    "    torch.save(tensor_depth_images_no_rgb, \"VALID_tensors/VALID_tensor_depth_images_no_rgb.pt\")\n",
    "    \n",
    "    return tensor_images,tensor_depth_images,tensor_depth_images_no_rgb #delete from memory\n",
    "\n",
    "    \n",
    "    #return(tensor_images,tensor_depth_images)\n",
    "data = create_data_valid(dataset_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
