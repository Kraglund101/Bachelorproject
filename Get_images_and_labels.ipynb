{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88265fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f6faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"C:/Users/frede/Desktop/Bachelorprojekt/datasets/VALID-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b733f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a custom dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.Tensor(self.data[idx])\n",
    "        y = torch.Tensor(self.targets[idx])\n",
    "        \n",
    "        return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c022cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_from_json(json_path):\n",
    "    f = open(json_path)\n",
    "    json_file = json.load(f)\n",
    "    path_to_image_file = json_file[\"file_name\"]\n",
    "    \n",
    "    return(f\"C:/Users/frede/Desktop/Bachelorprojekt/datasets/VALID-dataset/{path_to_image_file}\")\n",
    "\n",
    "def find_image_from_json_simple(json_path):\n",
    "    f = open(json_path)\n",
    "    json_file = json.load(f)\n",
    "    path_to_image_file = json_file[\"file_name\"]\n",
    "    #print(path_to_image_file)\n",
    "    \n",
    "    return(os.path.join(dataset_dir,path_to_image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "640f145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "tens1 = torch.randn(10,3,1000,1000)\n",
    "tens2 = torch.randn(10,1000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbac7c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input size: amount_img, channels, width, height\n",
    "def resize_256_256(inp):\n",
    "    return(F.interpolate(inp, size=(256,256), mode=\"bilinear\", align_corners=False))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371d4f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"C:/Users/frede/Desktop/Bachelorprojekt/datasets/VALID-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0169063",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11176\\3053474565.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtensor_depth_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11176\\3053474565.py\u001b[0m in \u001b[0;36mcreate_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m# Read in image and depth image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mdepth_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_depth_image_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_data():\n",
    "    start_time = time.time()\n",
    "\n",
    "    images_list = []\n",
    "    depth_images_list = []\n",
    "    #transform\n",
    "    for tup in zip(os.listdir(os.path.join(dataset_dir,\"depth\")), os.listdir(os.path.join(dataset_dir,\"label\"))):\n",
    "        \n",
    "        # Path to image and depth image\n",
    "        current_image_path = find_image_from_json_simple(os.path.join(dataset_dir, \"label\", tup[1]))\n",
    "        current_depth_image_path = os.path.join(dataset_dir,\"depth\", tup[0])\n",
    "\n",
    "        # Read in image and depth image\n",
    "        image = cv2.imread(current_image_path)/256\n",
    "        depth_image = cv2.imread(current_depth_image_path)/256\n",
    "        \n",
    "        \n",
    "        #print(depth_image.shape)\n",
    "        # Convert image and depth image to tensors: shape from (1024,1024,3) to (1,3,1024,1024) -> (256,256,3) to (1,3,256,256)\n",
    "        image = resize_256_256(torch.from_numpy(image).unsqueeze(0).permute(0,3,1,2))\n",
    "        \n",
    "        # Convert image and depth image to tensors: shape from (1024,1024,3) to (1,3,1024,1024) -> (256,256,3) to (1,3,256,256) to (1,256,256)\n",
    "        depth_image = resize_256_256(torch.from_numpy(depth_image).unsqueeze(0).permute(0,3,1,2))[:,0,:,:]\n",
    "        \n",
    "\n",
    "        # Add image tensor and depth image tensor to lists\n",
    "        images_list.append(image)\n",
    "        depth_images_list.append(depth_image)\n",
    "        \n",
    "\n",
    "           \n",
    "    tensor_images = torch.cat(images_list,dim=0)\n",
    "    tensor_depth_images = torch.cat(depth_images_list, dim=0)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    return(tensor_images,tensor_depth_images)\n",
    "train_data = create_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94207c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
